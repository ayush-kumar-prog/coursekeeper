# Computer Vision Research Papers - 2024

**Generated:** 10/17/2025, 2:46:01 PM

**Total Topics:** 5

**Total Papers:** 50

---

## Table of Contents

1. [Diffusion Models](#diffusion-models) (10 papers)
2. [Vision-Language Models](#vision-language) (10 papers)
3. [3D Reconstruction](#3d-reconstruction) (10 papers)
4. [Video Understanding](#video-understanding) (10 papers)
5. [Vision Foundation Models](#foundation-models) (10 papers)

---

## 1. Diffusion Models

**Query:** `diffusion models image generation`

**Description:** Diffusion-based generative models for image synthesis and editing

**Papers Found:** 10

### 1.1 MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics

- **Authors:** Yuxing Lu, Xukai Zhao, J. Ben Tamo, Micky C. Nnamdi, Rui Peng, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14944](https://arxiv.org/abs/2510.14944)
- **Categories:** cs.CL, cs.AI, cs.CE
- **PDF:** [Download](https://arxiv.org/pdf/2510.14944.pdf)

**Abstract:**

> Large Language Models (LLMs) have demonstrated remarkable capabilities on general text; however, their proficiency in specialized scientific domains that require deep, interconnected knowledge remains largely uncharacterized. Metabolomics presents unique challenges with its complex biochemical pathways, heterogeneous identifier systems, and fragmented databases. To systematically evaluate LLM capabilities in this domain, we introduce MetaBench, the first benchmark for metabolomics assessment. Cu...

---

### 1.2 Decoding in the presence of ISI without interleaving ORBGRAND AI

- **Authors:** Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
- **Year:** 2025
- **arXiv ID:** [2510.14939](https://arxiv.org/abs/2510.14939)
- **Categories:** eess.SP
- **PDF:** [Download](https://arxiv.org/pdf/2510.14939.pdf)

**Abstract:**

> Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the s...

---

### 1.3 AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations

- **Authors:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin
- **Year:** 2025
- **arXiv ID:** [2510.14937](https://arxiv.org/abs/2510.14937)
- **Categories:** cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14937.pdf)

**Abstract:**

> Mental health disorders remain among the leading cause of disability worldwide, yet conditions such as depression, anxiety, and Post-Traumatic Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to subjective assessments, limited clinical resources, and stigma and low awareness. In primary care settings, studies show that providers misidentify depression or anxiety in over 60% of cases, highlighting the urgent need for scalable, accessible, and context-aware diagnostic tools...

---

### 1.4 Circuit Insights: Towards Interpretability Beyond Activations

- **Authors:** Elena Golimblevskaia, Aakriti Jain, Bruno Puri, Ammar Ibrahim, Wojciech Samek, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14936](https://arxiv.org/abs/2510.14936)
- **Categories:** cs.LG, cs.AI, cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14936.pdf)

**Abstract:**

> The fields of explainable AI and mechanistic interpretability aim to uncover the internal structure of neural networks, with circuit discovery as a central tool for understanding model computations. Existing approaches, however, rely on manual inspection and remain limited to toy tasks. Automated interpretability offers scalability by analyzing isolated features and their activations, but it often misses interactions between features and depends strongly on external LLMs and dataset quality. Tra...

---

### 1.5 Instruction Set Migration at Warehouse Scale

- **Authors:** Eric Christopher, Kevin Crossan, Wolff Dobson, Chris Kennelly, Drew Lewis, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14928](https://arxiv.org/abs/2510.14928)
- **Categories:** cs.SE, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14928.pdf)

**Abstract:**

> Migrating codebases from one instruction set architecture (ISA) to another is a major engineering challenge. A recent example is the adoption of Arm (in addition to x86) across the major Cloud hyperscalers. Yet, this problem has seen limited attention by the academic community. Most work has focused on static and dynamic binary translation, and the traditional conventional wisdom has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA mig...

---

### 1.6 Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards

- **Authors:** Sarah Liaw, Benjamin Plaut
- **Year:** 2025
- **arXiv ID:** [2510.14884](https://arxiv.org/abs/2510.14884)
- **Categories:** cs.LG, cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14884.pdf)

**Abstract:**

> In high-stakes AI applications, even a single action can cause irreparable damage. However, nearly all of sequential decision-making theory assumes that all errors are recoverable (e.g., by bounding rewards). Standard bandit algorithms that explore aggressively may cause irreparable damage when this assumption fails. Some prior work avoids irreparable errors by asking for help from a mentor, but a mentor may not always be available. In this work, we formalize a model of learning with unbounded r...

---

### 1.7 The Gatekeeper Knows Enough

- **Authors:** Fikresilase Wondmeneh Abebayew
- **Year:** 2025
- **arXiv ID:** [2510.14881](https://arxiv.org/abs/2510.14881)
- **Categories:** cs.AI, cs.IT
- **PDF:** [Download](https://arxiv.org/pdf/2510.14881.pdf)

**Abstract:**

> Large Language Models (LLMs) are increasingly deployed as autonomous agents, yet their practical utility is fundamentally constrained by a limited context window and state desynchronization resulting from the LLMs' stateless nature and inefficient context management. These limitations lead to unreliable output, unpredictable behavior, and inefficient resource usage, particularly when interacting with large, structured, and sensitive knowledge systems such as codebases and documents. To address t...

---

### 1.8 From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR

- **Authors:** Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14871](https://arxiv.org/abs/2510.14871)
- **Categories:** cs.CL, cs.AR, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14871.pdf)

**Abstract:**

> General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR ...

---

### 1.9 LabOS: The AI-XR Co-Scientist That Sees and Works With Humans

- **Authors:** Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14861](https://arxiv.org/abs/2510.14861)
- **Categories:** cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14861.pdf)

**Abstract:**

> Modern science advances fastest when thought meets action. LabOS represents the first AI co-scientist that unites computational reasoning with physical experimentation through multimodal perception, self-evolving agents, and Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see what scientists see, understand experimental context, and assist in real-time execution. Across applications--from canc...

---

### 1.10 Where to Search: Measure the Prior-Structured Search Space of LLM Agents

- **Authors:** Zhuo-Yang Song
- **Year:** 2025
- **arXiv ID:** [2510.14846](https://arxiv.org/abs/2510.14846)
- **Categories:** cs.AI, cs.CL, cs.LO
- **PDF:** [Download](https://arxiv.org/pdf/2510.14846.pdf)

**Abstract:**

> The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science. However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space. To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors. We represent an agent as a fuzzy ...

---

## 2. Vision-Language Models

**Query:** `vision language models multimodal`

**Description:** Multimodal models combining vision and language understanding

**Papers Found:** 10

### 2.1 MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics

- **Authors:** Yuxing Lu, Xukai Zhao, J. Ben Tamo, Micky C. Nnamdi, Rui Peng, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14944](https://arxiv.org/abs/2510.14944)
- **Categories:** cs.CL, cs.AI, cs.CE
- **PDF:** [Download](https://arxiv.org/pdf/2510.14944.pdf)

**Abstract:**

> Large Language Models (LLMs) have demonstrated remarkable capabilities on general text; however, their proficiency in specialized scientific domains that require deep, interconnected knowledge remains largely uncharacterized. Metabolomics presents unique challenges with its complex biochemical pathways, heterogeneous identifier systems, and fragmented databases. To systematically evaluate LLM capabilities in this domain, we introduce MetaBench, the first benchmark for metabolomics assessment. Cu...

---

### 2.2 Decoding in the presence of ISI without interleaving ORBGRAND AI

- **Authors:** Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
- **Year:** 2025
- **arXiv ID:** [2510.14939](https://arxiv.org/abs/2510.14939)
- **Categories:** eess.SP
- **PDF:** [Download](https://arxiv.org/pdf/2510.14939.pdf)

**Abstract:**

> Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the s...

---

### 2.3 AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations

- **Authors:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin
- **Year:** 2025
- **arXiv ID:** [2510.14937](https://arxiv.org/abs/2510.14937)
- **Categories:** cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14937.pdf)

**Abstract:**

> Mental health disorders remain among the leading cause of disability worldwide, yet conditions such as depression, anxiety, and Post-Traumatic Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to subjective assessments, limited clinical resources, and stigma and low awareness. In primary care settings, studies show that providers misidentify depression or anxiety in over 60% of cases, highlighting the urgent need for scalable, accessible, and context-aware diagnostic tools...

---

### 2.4 Circuit Insights: Towards Interpretability Beyond Activations

- **Authors:** Elena Golimblevskaia, Aakriti Jain, Bruno Puri, Ammar Ibrahim, Wojciech Samek, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14936](https://arxiv.org/abs/2510.14936)
- **Categories:** cs.LG, cs.AI, cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14936.pdf)

**Abstract:**

> The fields of explainable AI and mechanistic interpretability aim to uncover the internal structure of neural networks, with circuit discovery as a central tool for understanding model computations. Existing approaches, however, rely on manual inspection and remain limited to toy tasks. Automated interpretability offers scalability by analyzing isolated features and their activations, but it often misses interactions between features and depends strongly on external LLMs and dataset quality. Tra...

---

### 2.5 Instruction Set Migration at Warehouse Scale

- **Authors:** Eric Christopher, Kevin Crossan, Wolff Dobson, Chris Kennelly, Drew Lewis, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14928](https://arxiv.org/abs/2510.14928)
- **Categories:** cs.SE, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14928.pdf)

**Abstract:**

> Migrating codebases from one instruction set architecture (ISA) to another is a major engineering challenge. A recent example is the adoption of Arm (in addition to x86) across the major Cloud hyperscalers. Yet, this problem has seen limited attention by the academic community. Most work has focused on static and dynamic binary translation, and the traditional conventional wisdom has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA mig...

---

### 2.6 Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards

- **Authors:** Sarah Liaw, Benjamin Plaut
- **Year:** 2025
- **arXiv ID:** [2510.14884](https://arxiv.org/abs/2510.14884)
- **Categories:** cs.LG, cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14884.pdf)

**Abstract:**

> In high-stakes AI applications, even a single action can cause irreparable damage. However, nearly all of sequential decision-making theory assumes that all errors are recoverable (e.g., by bounding rewards). Standard bandit algorithms that explore aggressively may cause irreparable damage when this assumption fails. Some prior work avoids irreparable errors by asking for help from a mentor, but a mentor may not always be available. In this work, we formalize a model of learning with unbounded r...

---

### 2.7 The Gatekeeper Knows Enough

- **Authors:** Fikresilase Wondmeneh Abebayew
- **Year:** 2025
- **arXiv ID:** [2510.14881](https://arxiv.org/abs/2510.14881)
- **Categories:** cs.AI, cs.IT
- **PDF:** [Download](https://arxiv.org/pdf/2510.14881.pdf)

**Abstract:**

> Large Language Models (LLMs) are increasingly deployed as autonomous agents, yet their practical utility is fundamentally constrained by a limited context window and state desynchronization resulting from the LLMs' stateless nature and inefficient context management. These limitations lead to unreliable output, unpredictable behavior, and inefficient resource usage, particularly when interacting with large, structured, and sensitive knowledge systems such as codebases and documents. To address t...

---

### 2.8 From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR

- **Authors:** Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14871](https://arxiv.org/abs/2510.14871)
- **Categories:** cs.CL, cs.AR, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14871.pdf)

**Abstract:**

> General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR ...

---

### 2.9 LabOS: The AI-XR Co-Scientist That Sees and Works With Humans

- **Authors:** Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14861](https://arxiv.org/abs/2510.14861)
- **Categories:** cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14861.pdf)

**Abstract:**

> Modern science advances fastest when thought meets action. LabOS represents the first AI co-scientist that unites computational reasoning with physical experimentation through multimodal perception, self-evolving agents, and Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see what scientists see, understand experimental context, and assist in real-time execution. Across applications--from canc...

---

### 2.10 Where to Search: Measure the Prior-Structured Search Space of LLM Agents

- **Authors:** Zhuo-Yang Song
- **Year:** 2025
- **arXiv ID:** [2510.14846](https://arxiv.org/abs/2510.14846)
- **Categories:** cs.AI, cs.CL, cs.LO
- **PDF:** [Download](https://arxiv.org/pdf/2510.14846.pdf)

**Abstract:**

> The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science. However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space. To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors. We represent an agent as a fuzzy ...

---

## 3. 3D Reconstruction

**Query:** `3D reconstruction neural radiance fields NeRF`

**Description:** Neural 3D scene reconstruction and novel view synthesis

**Papers Found:** 10

### 3.1 MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics

- **Authors:** Yuxing Lu, Xukai Zhao, J. Ben Tamo, Micky C. Nnamdi, Rui Peng, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14944](https://arxiv.org/abs/2510.14944)
- **Categories:** cs.CL, cs.AI, cs.CE
- **PDF:** [Download](https://arxiv.org/pdf/2510.14944.pdf)

**Abstract:**

> Large Language Models (LLMs) have demonstrated remarkable capabilities on general text; however, their proficiency in specialized scientific domains that require deep, interconnected knowledge remains largely uncharacterized. Metabolomics presents unique challenges with its complex biochemical pathways, heterogeneous identifier systems, and fragmented databases. To systematically evaluate LLM capabilities in this domain, we introduce MetaBench, the first benchmark for metabolomics assessment. Cu...

---

### 3.2 Decoding in the presence of ISI without interleaving ORBGRAND AI

- **Authors:** Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
- **Year:** 2025
- **arXiv ID:** [2510.14939](https://arxiv.org/abs/2510.14939)
- **Categories:** eess.SP
- **PDF:** [Download](https://arxiv.org/pdf/2510.14939.pdf)

**Abstract:**

> Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the s...

---

### 3.3 AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations

- **Authors:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin
- **Year:** 2025
- **arXiv ID:** [2510.14937](https://arxiv.org/abs/2510.14937)
- **Categories:** cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14937.pdf)

**Abstract:**

> Mental health disorders remain among the leading cause of disability worldwide, yet conditions such as depression, anxiety, and Post-Traumatic Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to subjective assessments, limited clinical resources, and stigma and low awareness. In primary care settings, studies show that providers misidentify depression or anxiety in over 60% of cases, highlighting the urgent need for scalable, accessible, and context-aware diagnostic tools...

---

### 3.4 Circuit Insights: Towards Interpretability Beyond Activations

- **Authors:** Elena Golimblevskaia, Aakriti Jain, Bruno Puri, Ammar Ibrahim, Wojciech Samek, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14936](https://arxiv.org/abs/2510.14936)
- **Categories:** cs.LG, cs.AI, cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14936.pdf)

**Abstract:**

> The fields of explainable AI and mechanistic interpretability aim to uncover the internal structure of neural networks, with circuit discovery as a central tool for understanding model computations. Existing approaches, however, rely on manual inspection and remain limited to toy tasks. Automated interpretability offers scalability by analyzing isolated features and their activations, but it often misses interactions between features and depends strongly on external LLMs and dataset quality. Tra...

---

### 3.5 Instruction Set Migration at Warehouse Scale

- **Authors:** Eric Christopher, Kevin Crossan, Wolff Dobson, Chris Kennelly, Drew Lewis, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14928](https://arxiv.org/abs/2510.14928)
- **Categories:** cs.SE, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14928.pdf)

**Abstract:**

> Migrating codebases from one instruction set architecture (ISA) to another is a major engineering challenge. A recent example is the adoption of Arm (in addition to x86) across the major Cloud hyperscalers. Yet, this problem has seen limited attention by the academic community. Most work has focused on static and dynamic binary translation, and the traditional conventional wisdom has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA mig...

---

### 3.6 Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards

- **Authors:** Sarah Liaw, Benjamin Plaut
- **Year:** 2025
- **arXiv ID:** [2510.14884](https://arxiv.org/abs/2510.14884)
- **Categories:** cs.LG, cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14884.pdf)

**Abstract:**

> In high-stakes AI applications, even a single action can cause irreparable damage. However, nearly all of sequential decision-making theory assumes that all errors are recoverable (e.g., by bounding rewards). Standard bandit algorithms that explore aggressively may cause irreparable damage when this assumption fails. Some prior work avoids irreparable errors by asking for help from a mentor, but a mentor may not always be available. In this work, we formalize a model of learning with unbounded r...

---

### 3.7 The Gatekeeper Knows Enough

- **Authors:** Fikresilase Wondmeneh Abebayew
- **Year:** 2025
- **arXiv ID:** [2510.14881](https://arxiv.org/abs/2510.14881)
- **Categories:** cs.AI, cs.IT
- **PDF:** [Download](https://arxiv.org/pdf/2510.14881.pdf)

**Abstract:**

> Large Language Models (LLMs) are increasingly deployed as autonomous agents, yet their practical utility is fundamentally constrained by a limited context window and state desynchronization resulting from the LLMs' stateless nature and inefficient context management. These limitations lead to unreliable output, unpredictable behavior, and inefficient resource usage, particularly when interacting with large, structured, and sensitive knowledge systems such as codebases and documents. To address t...

---

### 3.8 From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR

- **Authors:** Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14871](https://arxiv.org/abs/2510.14871)
- **Categories:** cs.CL, cs.AR, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14871.pdf)

**Abstract:**

> General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR ...

---

### 3.9 LabOS: The AI-XR Co-Scientist That Sees and Works With Humans

- **Authors:** Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14861](https://arxiv.org/abs/2510.14861)
- **Categories:** cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14861.pdf)

**Abstract:**

> Modern science advances fastest when thought meets action. LabOS represents the first AI co-scientist that unites computational reasoning with physical experimentation through multimodal perception, self-evolving agents, and Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see what scientists see, understand experimental context, and assist in real-time execution. Across applications--from canc...

---

### 3.10 Where to Search: Measure the Prior-Structured Search Space of LLM Agents

- **Authors:** Zhuo-Yang Song
- **Year:** 2025
- **arXiv ID:** [2510.14846](https://arxiv.org/abs/2510.14846)
- **Categories:** cs.AI, cs.CL, cs.LO
- **PDF:** [Download](https://arxiv.org/pdf/2510.14846.pdf)

**Abstract:**

> The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science. However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space. To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors. We represent an agent as a fuzzy ...

---

## 4. Video Understanding

**Query:** `video understanding temporal action recognition`

**Description:** Temporal modeling and action recognition in videos

**Papers Found:** 10

### 4.1 MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics

- **Authors:** Yuxing Lu, Xukai Zhao, J. Ben Tamo, Micky C. Nnamdi, Rui Peng, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14944](https://arxiv.org/abs/2510.14944)
- **Categories:** cs.CL, cs.AI, cs.CE
- **PDF:** [Download](https://arxiv.org/pdf/2510.14944.pdf)

**Abstract:**

> Large Language Models (LLMs) have demonstrated remarkable capabilities on general text; however, their proficiency in specialized scientific domains that require deep, interconnected knowledge remains largely uncharacterized. Metabolomics presents unique challenges with its complex biochemical pathways, heterogeneous identifier systems, and fragmented databases. To systematically evaluate LLM capabilities in this domain, we introduce MetaBench, the first benchmark for metabolomics assessment. Cu...

---

### 4.2 Decoding in the presence of ISI without interleaving ORBGRAND AI

- **Authors:** Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
- **Year:** 2025
- **arXiv ID:** [2510.14939](https://arxiv.org/abs/2510.14939)
- **Categories:** eess.SP
- **PDF:** [Download](https://arxiv.org/pdf/2510.14939.pdf)

**Abstract:**

> Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the s...

---

### 4.3 AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations

- **Authors:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin
- **Year:** 2025
- **arXiv ID:** [2510.14937](https://arxiv.org/abs/2510.14937)
- **Categories:** cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14937.pdf)

**Abstract:**

> Mental health disorders remain among the leading cause of disability worldwide, yet conditions such as depression, anxiety, and Post-Traumatic Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to subjective assessments, limited clinical resources, and stigma and low awareness. In primary care settings, studies show that providers misidentify depression or anxiety in over 60% of cases, highlighting the urgent need for scalable, accessible, and context-aware diagnostic tools...

---

### 4.4 Circuit Insights: Towards Interpretability Beyond Activations

- **Authors:** Elena Golimblevskaia, Aakriti Jain, Bruno Puri, Ammar Ibrahim, Wojciech Samek, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14936](https://arxiv.org/abs/2510.14936)
- **Categories:** cs.LG, cs.AI, cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14936.pdf)

**Abstract:**

> The fields of explainable AI and mechanistic interpretability aim to uncover the internal structure of neural networks, with circuit discovery as a central tool for understanding model computations. Existing approaches, however, rely on manual inspection and remain limited to toy tasks. Automated interpretability offers scalability by analyzing isolated features and their activations, but it often misses interactions between features and depends strongly on external LLMs and dataset quality. Tra...

---

### 4.5 Instruction Set Migration at Warehouse Scale

- **Authors:** Eric Christopher, Kevin Crossan, Wolff Dobson, Chris Kennelly, Drew Lewis, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14928](https://arxiv.org/abs/2510.14928)
- **Categories:** cs.SE, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14928.pdf)

**Abstract:**

> Migrating codebases from one instruction set architecture (ISA) to another is a major engineering challenge. A recent example is the adoption of Arm (in addition to x86) across the major Cloud hyperscalers. Yet, this problem has seen limited attention by the academic community. Most work has focused on static and dynamic binary translation, and the traditional conventional wisdom has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA mig...

---

### 4.6 Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards

- **Authors:** Sarah Liaw, Benjamin Plaut
- **Year:** 2025
- **arXiv ID:** [2510.14884](https://arxiv.org/abs/2510.14884)
- **Categories:** cs.LG, cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14884.pdf)

**Abstract:**

> In high-stakes AI applications, even a single action can cause irreparable damage. However, nearly all of sequential decision-making theory assumes that all errors are recoverable (e.g., by bounding rewards). Standard bandit algorithms that explore aggressively may cause irreparable damage when this assumption fails. Some prior work avoids irreparable errors by asking for help from a mentor, but a mentor may not always be available. In this work, we formalize a model of learning with unbounded r...

---

### 4.7 The Gatekeeper Knows Enough

- **Authors:** Fikresilase Wondmeneh Abebayew
- **Year:** 2025
- **arXiv ID:** [2510.14881](https://arxiv.org/abs/2510.14881)
- **Categories:** cs.AI, cs.IT
- **PDF:** [Download](https://arxiv.org/pdf/2510.14881.pdf)

**Abstract:**

> Large Language Models (LLMs) are increasingly deployed as autonomous agents, yet their practical utility is fundamentally constrained by a limited context window and state desynchronization resulting from the LLMs' stateless nature and inefficient context management. These limitations lead to unreliable output, unpredictable behavior, and inefficient resource usage, particularly when interacting with large, structured, and sensitive knowledge systems such as codebases and documents. To address t...

---

### 4.8 From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR

- **Authors:** Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14871](https://arxiv.org/abs/2510.14871)
- **Categories:** cs.CL, cs.AR, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14871.pdf)

**Abstract:**

> General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR ...

---

### 4.9 LabOS: The AI-XR Co-Scientist That Sees and Works With Humans

- **Authors:** Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14861](https://arxiv.org/abs/2510.14861)
- **Categories:** cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14861.pdf)

**Abstract:**

> Modern science advances fastest when thought meets action. LabOS represents the first AI co-scientist that unites computational reasoning with physical experimentation through multimodal perception, self-evolving agents, and Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see what scientists see, understand experimental context, and assist in real-time execution. Across applications--from canc...

---

### 4.10 Where to Search: Measure the Prior-Structured Search Space of LLM Agents

- **Authors:** Zhuo-Yang Song
- **Year:** 2025
- **arXiv ID:** [2510.14846](https://arxiv.org/abs/2510.14846)
- **Categories:** cs.AI, cs.CL, cs.LO
- **PDF:** [Download](https://arxiv.org/pdf/2510.14846.pdf)

**Abstract:**

> The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science. However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space. To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors. We represent an agent as a fuzzy ...

---

## 5. Vision Foundation Models

**Query:** `vision foundation models self-supervised learning`

**Description:** Large-scale pre-trained models for computer vision

**Papers Found:** 10

### 5.1 MetaBench: A Multi-task Benchmark for Assessing LLMs in Metabolomics

- **Authors:** Yuxing Lu, Xukai Zhao, J. Ben Tamo, Micky C. Nnamdi, Rui Peng, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14944](https://arxiv.org/abs/2510.14944)
- **Categories:** cs.CL, cs.AI, cs.CE
- **PDF:** [Download](https://arxiv.org/pdf/2510.14944.pdf)

**Abstract:**

> Large Language Models (LLMs) have demonstrated remarkable capabilities on general text; however, their proficiency in specialized scientific domains that require deep, interconnected knowledge remains largely uncharacterized. Metabolomics presents unique challenges with its complex biochemical pathways, heterogeneous identifier systems, and fragmented databases. To systematically evaluate LLM capabilities in this domain, we introduce MetaBench, the first benchmark for metabolomics assessment. Cu...

---

### 5.2 Decoding in the presence of ISI without interleaving ORBGRAND AI

- **Authors:** Ken R. Duffy, Moritz Grundei, Jane A. Millward, Muralidhar Rangaswamy, Muriel Medard
- **Year:** 2025
- **arXiv ID:** [2510.14939](https://arxiv.org/abs/2510.14939)
- **Categories:** eess.SP
- **PDF:** [Download](https://arxiv.org/pdf/2510.14939.pdf)

**Abstract:**

> Inter symbol interference (ISI), which occurs in a wide variety of channels, is a result of time dispersion. It can be mitigated by equalization which results in noise coloring. For such colored noise, we propose a decoder called Ordered Reliability Bit Guessing Random Additive Noise Decoding (ORBGRANDAI) which is inspired by the development of approximate independence in statistical physics. By foregoing interleaving, ORBGRAND-AI can deliver the same, or lower, block error rate (BLER) for the s...

---

### 5.3 AI-Powered Early Diagnosis of Mental Health Disorders from Real-World Clinical Conversations

- **Authors:** Jianfeng Zhu, Julina Maharjan, Xinyu Li, Karin G. Coifman, Ruoming Jin
- **Year:** 2025
- **arXiv ID:** [2510.14937](https://arxiv.org/abs/2510.14937)
- **Categories:** cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14937.pdf)

**Abstract:**

> Mental health disorders remain among the leading cause of disability worldwide, yet conditions such as depression, anxiety, and Post-Traumatic Stress Disorder (PTSD) are frequently underdiagnosed or misdiagnosed due to subjective assessments, limited clinical resources, and stigma and low awareness. In primary care settings, studies show that providers misidentify depression or anxiety in over 60% of cases, highlighting the urgent need for scalable, accessible, and context-aware diagnostic tools...

---

### 5.4 Circuit Insights: Towards Interpretability Beyond Activations

- **Authors:** Elena Golimblevskaia, Aakriti Jain, Bruno Puri, Ammar Ibrahim, Wojciech Samek, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14936](https://arxiv.org/abs/2510.14936)
- **Categories:** cs.LG, cs.AI, cs.CL
- **PDF:** [Download](https://arxiv.org/pdf/2510.14936.pdf)

**Abstract:**

> The fields of explainable AI and mechanistic interpretability aim to uncover the internal structure of neural networks, with circuit discovery as a central tool for understanding model computations. Existing approaches, however, rely on manual inspection and remain limited to toy tasks. Automated interpretability offers scalability by analyzing isolated features and their activations, but it often misses interactions between features and depends strongly on external LLMs and dataset quality. Tra...

---

### 5.5 Instruction Set Migration at Warehouse Scale

- **Authors:** Eric Christopher, Kevin Crossan, Wolff Dobson, Chris Kennelly, Drew Lewis, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14928](https://arxiv.org/abs/2510.14928)
- **Categories:** cs.SE, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14928.pdf)

**Abstract:**

> Migrating codebases from one instruction set architecture (ISA) to another is a major engineering challenge. A recent example is the adoption of Arm (in addition to x86) across the major Cloud hyperscalers. Yet, this problem has seen limited attention by the academic community. Most work has focused on static and dynamic binary translation, and the traditional conventional wisdom has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA mig...

---

### 5.6 Learning When Not to Learn: Risk-Sensitive Abstention in Bandits with Unbounded Rewards

- **Authors:** Sarah Liaw, Benjamin Plaut
- **Year:** 2025
- **arXiv ID:** [2510.14884](https://arxiv.org/abs/2510.14884)
- **Categories:** cs.LG, cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14884.pdf)

**Abstract:**

> In high-stakes AI applications, even a single action can cause irreparable damage. However, nearly all of sequential decision-making theory assumes that all errors are recoverable (e.g., by bounding rewards). Standard bandit algorithms that explore aggressively may cause irreparable damage when this assumption fails. Some prior work avoids irreparable errors by asking for help from a mentor, but a mentor may not always be available. In this work, we formalize a model of learning with unbounded r...

---

### 5.7 The Gatekeeper Knows Enough

- **Authors:** Fikresilase Wondmeneh Abebayew
- **Year:** 2025
- **arXiv ID:** [2510.14881](https://arxiv.org/abs/2510.14881)
- **Categories:** cs.AI, cs.IT
- **PDF:** [Download](https://arxiv.org/pdf/2510.14881.pdf)

**Abstract:**

> Large Language Models (LLMs) are increasingly deployed as autonomous agents, yet their practical utility is fundamentally constrained by a limited context window and state desynchronization resulting from the LLMs' stateless nature and inefficient context management. These limitations lead to unreliable output, unpredictable behavior, and inefficient resource usage, particularly when interacting with large, structured, and sensitive knowledge systems such as codebases and documents. To address t...

---

### 5.8 From Loop Nests to Silicon: Mapping AI Workloads onto AMD NPUs with MLIR-AIR

- **Authors:** Erwei Wang, Samuel Bayliss, Andra Bisca, Zachary Blair, Sangeeta Chowdhary, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14871](https://arxiv.org/abs/2510.14871)
- **Categories:** cs.CL, cs.AR, cs.LG
- **PDF:** [Download](https://arxiv.org/pdf/2510.14871.pdf)

**Abstract:**

> General-purpose compilers abstract away parallelism, locality, and synchronization, limiting their effectiveness on modern spatial architectures. As modern computing architectures increasingly rely on fine-grained control over data movement, execution order, and compute placement for performance, compiler infrastructure must provide explicit mechanisms for orchestrating compute and data to fully exploit such architectures. We introduce MLIR-AIR, a novel, open-source compiler stack built on MLIR ...

---

### 5.9 LabOS: The AI-XR Co-Scientist That Sees and Works With Humans

- **Authors:** Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, et al.
- **Year:** 2025
- **arXiv ID:** [2510.14861](https://arxiv.org/abs/2510.14861)
- **Categories:** cs.AI
- **PDF:** [Download](https://arxiv.org/pdf/2510.14861.pdf)

**Abstract:**

> Modern science advances fastest when thought meets action. LabOS represents the first AI co-scientist that unites computational reasoning with physical experimentation through multimodal perception, self-evolving agents, and Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see what scientists see, understand experimental context, and assist in real-time execution. Across applications--from canc...

---

### 5.10 Where to Search: Measure the Prior-Structured Search Space of LLM Agents

- **Authors:** Zhuo-Yang Song
- **Year:** 2025
- **arXiv ID:** [2510.14846](https://arxiv.org/abs/2510.14846)
- **Categories:** cs.AI, cs.CL, cs.LO
- **PDF:** [Download](https://arxiv.org/pdf/2510.14846.pdf)

**Abstract:**

> The generate-filter-refine (iterative paradigm) based on large language models (LLMs) has achieved progress in reasoning, programming, and program discovery in AI+Science. However, the effectiveness of search depends on where to search, namely, how to encode the domain prior into an operationally structured hypothesis space. To this end, this paper proposes a compact formal theory that describes and measures LLM-assisted iterative search guided by domain priors. We represent an agent as a fuzzy ...

---

## Summary Statistics

| Topic | Papers Found |
|-------|-------------|
| Diffusion Models | 10 |
| Vision-Language Models | 10 |
| 3D Reconstruction | 10 |
| Video Understanding | 10 |
| Vision Foundation Models | 10 |

